{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bf42d78",
   "metadata": {},
   "source": [
    "Bin's comment:\n",
    "\n",
    "**NOT COMPLETED**\n",
    "\n",
    "Last modified on 4/13"
   ]
  },
  {
   "cell_type": "raw",
   "id": "317bd0c1",
   "metadata": {},
   "source": [
    "***This block is not code\n",
    "***Read before running the notebook\n",
    "\n",
    "CREATE folder paths manually as:\n",
    "ROOT\n",
    "    |-model\n",
    "    |\n",
    "    |-dataset\n",
    "    |    |-X_train_input\n",
    "    |    |-X_train_target\n",
    "    |    |-X_test_input\n",
    "    |    |-X_test_target\n",
    "    |\n",
    "    |-main.ipynb\n",
    "    |\n",
    "    |-discarded_code\n",
    "\n",
    "The dataset is from:\n",
    "https://www.kaggle.com/datasets/sanglequang/brats-2018-full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29ddfb74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T05:38:53.582997Z",
     "start_time": "2023-04-13T05:38:51.827602Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import SimpleITK as sitk\n",
    "import torch.optim as optim\n",
    "\n",
    "from UNet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "456a6559",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T05:38:55.350922Z",
     "start_time": "2023-04-13T05:38:53.583996Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config():\n",
    "    batch_size = 16\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    epochs = 4\n",
    "    warmup = 0.1\n",
    "    lr = 1e-5\n",
    "    T_0 = 100  # period of the first restart, we do not want it to restart, so we set it a big number\n",
    "    T_mult = 1  # period multiplier, it does not matter\n",
    "    eta_min = lr/10  # minimum learning rate\n",
    "    len_train_dataloader = None\n",
    "    len_valid_dataloader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbb02826",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T05:38:55.366931Z",
     "start_time": "2023-04-13T05:38:55.351922Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set SEED here # to be completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fdf42b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T05:38:55.382192Z",
     "start_time": "2023-04-13T05:38:55.367931Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = 'dataset'\n",
    "TRAIN_X_PATH = os.path.join(DATASET_PATH, 'X_train_input')\n",
    "VALID_X_PATH = os.path.join(DATASET_PATH, 'X_test_input')\n",
    "TRAIN_Y_PATH = os.path.join(DATASET_PATH, 'X_train_target')\n",
    "VALID_Y_PATH = os.path.join(DATASET_PATH, 'X_test_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84398280",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T05:38:55.446208Z",
     "start_time": "2023-04-13T05:38:55.383194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35340"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_train = len(os.listdir(TRAIN_X_PATH))\n",
    "Config.len_train_dataloader = len_train//Config.batch_size\n",
    "len_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49ed641c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T05:38:55.462211Z",
     "start_time": "2023-04-13T05:38:55.447207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8835"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_valid = len(os.listdir(VALID_X_PATH))\n",
    "Config.len_valid_dataloader = len_valid//Config.batch_size\n",
    "len_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11c5a03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T01:16:15.971437Z",
     "start_time": "2023-04-13T01:16:15.964435Z"
    }
   },
   "source": [
    "The index of TRAIN SET ranges from 0 to 35339 (end included)\n",
    "\n",
    "The index of VALID SET ranges from 0 to 8834 (end included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9ccbaaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T05:38:55.478214Z",
     "start_time": "2023-04-13T05:38:55.463211Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_loader(mode, x_or_y, index):\n",
    "    \"\"\"\n",
    "    Return the numpy image given the information.\n",
    "    mode: 'train', 'valid' or 'test'\n",
    "    x_or_y: 'x' or 'y', 'x' stands for the input and 'y' stands for the target\n",
    "    index: int, the index of the image\n",
    "    \"\"\"\n",
    "    if mode == 'train':\n",
    "        if x_or_y == 'x':\n",
    "            filepath = os.path.join(TRAIN_X_PATH, os.path.basename(TRAIN_X_PATH)+'_'+str(index)+'.npy')\n",
    "        if x_or_y == 'y':\n",
    "            filepath = os.path.join(TRAIN_Y_PATH, os.path.basename(TRAIN_Y_PATH)+'_'+str(index)+'.npy')\n",
    "    elif mode == 'valid':\n",
    "        if x_or_y == 'x':\n",
    "            filepath = os.path.join(VALID_X_PATH, os.path.basename(VALID_X_PATH)+'_'+str(index)+'.npy')\n",
    "        if x_or_y == 'y':\n",
    "            filepath = os.path.join(VALID_Y_PATH, os.path.basename(VALID_Y_PATH)+'_'+str(index)+'.npy')\n",
    "    else:\n",
    "        raise ValueError(\"The first or the second parameter is not valid\")\n",
    "        \n",
    "    if not isinstance(index, int):\n",
    "        raise TypeError(\"Index should be an integer\")\n",
    "    \n",
    "    if mode == 'train' and (index < 0 or index > 35339):\n",
    "            raise IndexError(\"Image index out of range 0 - 35339\")\n",
    "            \n",
    "    if mode == 'valid' and (index < 0 or index > 8834):\n",
    "            raise IndexError(\"Image index out of range 0 - 8834\")\n",
    "    \n",
    "    return np.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b0cc773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T05:38:55.494218Z",
     "start_time": "2023-04-13T05:38:55.480215Z"
    }
   },
   "outputs": [],
   "source": [
    "img_example = image_loader('valid', 'y', 560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06a9d38a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T05:38:55.686262Z",
     "start_time": "2023-04-13T05:38:55.496219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x234e7a56610>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e971e057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a2e36a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T05:38:55.702265Z",
     "start_time": "2023-04-13T05:38:55.687262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 240)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_loader('train', 'y', 6164).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5ca0a24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T05:38:55.718268Z",
     "start_time": "2023-04-13T05:38:55.703266Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 240, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_loader('train', 'x', 6164).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f521a6",
   "metadata": {},
   "source": [
    "**Bin's comment:**\n",
    "\n",
    "SimpleITK is a widely used package to transform medical images\n",
    "\n",
    "\n",
    "I dont know whether it is slower than other packages like torchvision transform\n",
    "You may define other transformation functions and compare them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebd62339",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T05:38:55.734272Z",
     "start_time": "2023-04-13T05:38:55.720269Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform(input_array, label_array):\n",
    "    \"\"\"\n",
    "    Data augmentation for training set.\n",
    "    input_array, label_array are in ndarray\n",
    "    \"\"\"\n",
    "    return input_array, label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314e6821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96748154",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T05:38:55.750276Z",
     "start_time": "2023-04-13T05:38:55.735273Z"
    }
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return len_train\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = image_loader('train', 'x', idx), image_loader('train', 'y', idx)\n",
    "        x = x.transpose((2, 0, 1))\n",
    "        x, y = transform(x, y)\n",
    "        return x, y # NOTE the permute, => Batch*Channel*Wright*Height\n",
    "    \n",
    "class ValidDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return len_valid\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = image_loader('valid', 'x', idx), image_loader('valid', 'y', idx)\n",
    "        x = x.transpose((2, 0, 1))\n",
    "        return x,y\n",
    "\n",
    "train_dataset = TrainDataset()\n",
    "valid_dataset = ValidDataset()\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=Config.batch_size, shuffle=True, drop_last=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=Config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c371837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d5bf5f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T05:38:58.492892Z",
     "start_time": "2023-04-13T05:38:55.751276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 240, 240])\n"
     ]
    }
   ],
   "source": [
    "#Test the model\n",
    "net = UNet(4, 5) # 4 channels, 5 classes (label 3 actually is ingored)\n",
    "y = net(torch.randn(8,4,240,240))\n",
    "_, y = torch.max(y, 1)\n",
    "print(y.size())\n",
    "del net, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5018b547",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T06:15:52.550197Z",
     "start_time": "2023-04-13T05:38:58.493892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 start\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd68fc53f934bbfaa92e556eaad4b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9754d90850940c0892d038f3c67029f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/552 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.4846, Valid Loss: 0.5147\n",
      "Epoch 2 start\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab00bccc884e421bbea8b5c6920a290c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cecdd153dd74e3cb86742ed11ab898b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/552 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.2033, Valid Loss: 0.2410\n",
      "Epoch 3 start\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32528377f594072b1b5ac209d849569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-0e19d10707ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# train for one epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# zero the parameter gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device=Config.device\n",
    "\n",
    "model = UNet(4,5)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=Config.lr)\n",
    "\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=Config.T_0, T_mult=Config.T_mult, eta_min=Config.eta_min)\n",
    "\n",
    "\n",
    "for epoch in range(Config.epochs):\n",
    "    print(\"Epoch \"+str(epoch+1)+\" start\")\n",
    "    model.train()\n",
    "    train_bar = tqdm(total=Config.len_train_dataloader)\n",
    "\n",
    "    for i, (inputs, targets) in enumerate(train_dataloader):\n",
    "        inputs, targets = inputs.to(device), targets.type(torch.LongTensor).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step(epoch + i/len(train_dataloader))\n",
    "        train_bar.update(1)\n",
    "        \n",
    "    train_bar.close()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    valid_bar = tqdm(total=Config.len_valid_dataloader)\n",
    "    with torch.no_grad():\n",
    "        valid_loss = 0.0\n",
    "        for j, (inputs, targets) in enumerate(valid_dataloader):\n",
    "            inputs, targets = inputs.to(device), targets.type(torch.LongTensor).to(device)\n",
    "\n",
    "            # forward\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            valid_bar.update(1)\n",
    "        valid_loss /= (j + 1)\n",
    "\n",
    "    valid_bar.close()\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {loss.item():.4f}, Valid Loss: {valid_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e69c158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f80b10e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc18754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
